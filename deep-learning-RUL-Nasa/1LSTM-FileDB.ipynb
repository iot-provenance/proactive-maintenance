{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aircraft Engine RUL Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#to plot the data\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('fivethirtyeight')\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler #to normalize data\n",
    "\n",
    "import os\n",
    "os.chdir(\"D:/RulNasa/\")\n",
    "\n",
    "#for deep learning\n",
    "import keras\n",
    "import keras.backend as k\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Activation, Masking, Dropout\n",
    "from keras.optimizers import RMSprop,adam\n",
    "from keras.callbacks import History\n",
    "from keras import callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# based on data wrangling python notebook\n",
    "def prepare_data(drop_cols = True):\n",
    "    dependent_var = ['RUL']\n",
    "    index_columns_names =  [\"UnitNumber\",\"Cycle\"]\n",
    "    sensor_measure_columns_names =[\"SensorMeasure\"+str(i) for i in range(1,22)]\n",
    "    input_file_column_names = index_columns_names + sensor_measure_columns_names\n",
    "\n",
    "    cols_to_drop = ['SensorMeasure1', 'SensorMeasure5', 'SensorMeasure6', 'SensorMeasure10', 'SensorMeasure14',\n",
    "     'SensorMeasure16', 'SensorMeasure18', 'SensorMeasure19']\n",
    "\n",
    "    df_train = pd.read_csv('train_FD004_1.txt',delim_whitespace=True,names=input_file_column_names)\n",
    "  \n",
    "    \n",
    "    rul = pd.DataFrame(df_train.groupby('UnitNumber')['Cycle'].max()).reset_index()\n",
    "    rul.columns = ['UnitNumber', 'max']\n",
    "    df_train = df_train.merge(rul, on=['UnitNumber'], how='left')\n",
    "    df_train['RUL'] = df_train['max'] - df_train['Cycle']\n",
    "    df_train.drop('max', axis=1, inplace=True)\n",
    "\n",
    "    df_test = pd.read_csv('train_FD004_2.txt', delim_whitespace=True, names=input_file_column_names)\n",
    "    \n",
    "    if(drop_cols == True):\n",
    "        df_train = df_train.drop(cols_to_drop, axis = 1)\n",
    "        df_test = df_test.drop(cols_to_drop, axis = 1)\n",
    "\n",
    "    y_true = pd.read_csv('RUL_FD004.txt', delim_whitespace=True,names=[\"RUL\"])\n",
    "    y_true[\"UnitNumber\"] = y_true.index\n",
    "    \n",
    "    return df_train, df_test, y_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure that variance of features remain in the same range, it is important to scale the features. If a feature's variance is order of magnitude more than the variance of other features, that particular feature might dominate other features in the dataset, which is not desirable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11249, 15)\n",
      "(50000, 16)\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test, y_true = prepare_data(drop_cols=True)\n",
    "df_train.shape, df_test.shape, y_true.shape\n",
    "\n",
    "feats = [column for column in df_train.columns if column !=\"RUL\"]\n",
    "\n",
    "min_max_scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "\n",
    "df_train[feats] = min_max_scaler.fit_transform(df_train[feats])\n",
    "df_test[feats] = min_max_scaler.fit_transform(df_test[feats])\n",
    "\n",
    "print(df_test.shape)\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "LSTM expects an input in the shape of a numpy array of 3 dimensions and I will need to convert train and test data accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gen_train(id_df, seq_length, seq_cols):\n",
    "    \"\"\"\n",
    "        function to prepare train data into (samples, time steps, features)\n",
    "        id_df = train dataframe\n",
    "        seq_length = look back period\n",
    "        seq_cols = feature columns\n",
    "    \"\"\"\n",
    "        \n",
    "    data_array = id_df[seq_cols].values\n",
    "    num_elements = data_array.shape[0]\n",
    "    \n",
    "    print(num_elements)\n",
    "    lstm_array=[]\n",
    "    \n",
    "    for start, stop in zip(range(0, num_elements-seq_length+1), range(seq_length, num_elements+1)):\n",
    "        lstm_array.append(data_array[start:stop, :])\n",
    "    \n",
    "    return np.array(lstm_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gen_target(id_df, seq_length, label):\n",
    "    data_array = id_df[label].values\n",
    "    num_elements = data_array.shape[0]\n",
    "    return data_array[seq_length-1:num_elements+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gen_test(id_df, seq_length, seq_cols, mask_value):\n",
    "    \"\"\"\n",
    "        function to prepare test data into (samples, time steps, features)\n",
    "        function only returns last sequence of data for every unit\n",
    "        id_df = test dataframe\n",
    "        seq_length = look back period\n",
    "        seq_cols = feature columns\n",
    "    \"\"\"\n",
    "  #  df_mask = pd.DataFrame(np.zeros((seq_length-1,id_df.shape[1])),columns=id_df.columns)\n",
    "   # df_mask[:] = mask_value\n",
    "    \n",
    "   # id_df = df_mask.append(id_df,ignore_index=True)\n",
    "    \n",
    "    data_array = id_df[seq_cols].values\n",
    "    num_elements = data_array.shape[0]\n",
    "    lstm_array=[]\n",
    "    \n",
    "    start = 0\n",
    "    #num_elements-seq_length\n",
    "    stop = num_elements\n",
    "    \n",
    "    lstm_array.append(data_array[start:stop, :])\n",
    "    \n",
    "    return np.array(lstm_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Let's define look back period and mask_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sequence_length = 50\n",
    "mask_value = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Let's prepare data using above functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10223\n",
      "188\n",
      "455\n",
      "201\n",
      "189\n",
      "207\n",
      "3786\n",
      "3850\n",
      "166\n",
      "174\n",
      "161\n",
      "193\n",
      "177\n",
      "189\n",
      "536\n",
      "3861\n",
      "180\n",
      "287\n",
      "525\n",
      "539\n",
      "3904\n",
      "179\n",
      "154\n",
      "184\n",
      "183\n",
      "483\n",
      "482\n",
      "171\n",
      "179\n",
      "185\n",
      "183\n",
      "505\n",
      "506\n",
      "165\n",
      "469\n",
      "190\n",
      "470\n",
      "489\n",
      "540\n",
      "193\n",
      "198\n",
      "176\n",
      "191\n",
      "207\n",
      "192\n",
      "210\n",
      "203\n",
      "190\n",
      "180\n",
      "189\n",
      "480\n",
      "516\n",
      "203\n",
      "99\n",
      "176\n",
      "181\n",
      "176\n",
      "194\n",
      "486\n",
      "182\n",
      "188\n",
      "525\n",
      "176\n",
      "518\n",
      "167\n",
      "190\n",
      "200\n",
      "196\n",
      "499\n",
      "199\n",
      "166\n",
      "518\n",
      "207\n",
      "176\n",
      "177\n",
      "212\n",
      "207\n",
      "154\n",
      "195\n",
      "193\n",
      "189\n",
      "84\n",
      "195\n",
      "214\n",
      "141\n",
      "196\n",
      "189\n",
      "193\n",
      "183\n",
      "186\n",
      "206\n",
      "206\n",
      "184\n",
      "187\n",
      "94\n",
      "187\n",
      "174\n",
      "192\n",
      "184\n",
      "174\n",
      "181\n",
      "194\n",
      "187\n",
      "98\n",
      "189\n",
      "(44855, 50, 15)\n"
     ]
    }
   ],
   "source": [
    "#generate train\n",
    "x_train=np.concatenate(list(list(gen_train(df_train[df_train['UnitNumber']==unit], sequence_length, feats)) for unit in df_train['UnitNumber'].unique()))\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44855,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generate target of train\n",
    "y_train = np.concatenate(list(list(gen_target(df_train[df_train['UnitNumber']==unit], sequence_length, \"RUL\")) for unit in df_train['UnitNumber'].unique()))\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2288\n",
      "113\n",
      "872\n",
      "103\n",
      "41\n",
      "112\n",
      "833\n",
      "825\n",
      "848\n",
      "32\n",
      "42\n",
      "43\n",
      "120\n",
      "114\n",
      "38\n",
      "45\n",
      "38\n",
      "35\n",
      "47\n",
      "40\n",
      "50\n",
      "46\n",
      "46\n",
      "39\n",
      "127\n",
      "36\n",
      "58\n",
      "121\n",
      "94\n",
      "112\n",
      "48\n",
      "45\n",
      "104\n",
      "41\n",
      "115\n",
      "46\n",
      "39\n",
      "38\n",
      "108\n",
      "37\n",
      "44\n",
      "128\n",
      "98\n",
      "138\n",
      "48\n",
      "51\n",
      "118\n",
      "39\n",
      "119\n",
      "50\n",
      "44\n",
      "51\n",
      "48\n",
      "48\n",
      "42\n",
      "104\n",
      "113\n",
      "41\n",
      "40\n",
      "48\n",
      "56\n",
      "53\n",
      "52\n",
      "49\n",
      "49\n",
      "31\n",
      "16\n",
      "44\n",
      "52\n",
      "30\n",
      "47\n",
      "44\n",
      "44\n",
      "47\n",
      "35\n",
      "37\n",
      "46\n",
      "57\n",
      "43\n",
      "41\n",
      "40\n",
      "43\n",
      "48\n",
      "46\n",
      "39\n",
      "36\n",
      "39\n",
      "46\n",
      "44\n",
      "39\n",
      "47\n",
      "46\n",
      "29\n",
      "54\n",
      "46\n",
      "35\n",
      "47\n",
      "47\n",
      "43\n",
      "30\n",
      "41\n",
      "21\n",
      "35\n",
      "18\n",
      "26\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 3 dimension(s) and the array at index 4 has 1 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#generate test\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m x_test\u001b[38;5;241m=\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgen_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf_test\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUnitNumber\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43munit\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msequence_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeats\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43munit\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdf_test\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUnitNumber\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(x_test\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 3 dimension(s) and the array at index 4 has 1 dimension(s)"
     ]
    }
   ],
   "source": [
    "#generate test\n",
    "x_test=np.concatenate(list(list(gen_train(df_test[df_test['UnitNumber']==unit], sequence_length, feats)) for unit in df_test['UnitNumber'].unique()))\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#true target of test \n",
    "y_test = y_true.RUL.values\n",
    "y_test.shape\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nb_features = x_train.shape[2]\n",
    "nb_out = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nb_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = History()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(\n",
    "         units=100,\n",
    "         return_sequences=True,\n",
    "         input_shape=(sequence_length, nb_features)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(\n",
    "          units=100,\n",
    "          return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=1, activation='relu'))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.compile(loss=\"mse\", optimizer=\"rmsprop\", metrics=['mse'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# fit the model\n",
    "model.fit(x_train, y_train, epochs=100, batch_size=32, validation_split=0.1, verbose=1,\n",
    "          callbacks = [history, keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='auto')])\n",
    "\n",
    "model.save('RUL_model.h5') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['mse'])\n",
    "plt.plot(history.history['val_mse'])\n",
    "plt.title('MSE')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.xlabel('# Epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results on Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "#establishing the connection\n",
    "conn = psycopg2.connect(\n",
    "   database=\"dataset\", user='postgres', password='0125527', host='127.0.0.1', port= '5432'\n",
    ")\n",
    "#Creating a cursor object using the cursor() method\n",
    "cursor = conn.cursor()\n",
    "\n",
    "#Executing an MYSQL function using the execute() method\n",
    "cursor.execute(\"select version()\")\n",
    "\n",
    "# Fetch a single row using fetchone() method.\n",
    "data = cursor.fetchone()\n",
    "print(\"Connection established to: \",data)\n",
    "\n",
    "#Closing the connection\n",
    "conn.close()\n",
    "\n",
    "#scores = model.evaluate(x_train, y_train, verbose=1, batch_size=200)\n",
    "#print('MSE: {}'.format(scores[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores_test = model.evaluate(x_test, y_test, verbose=2)\n",
    "print('MSE: {}'.format(scores_test[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred_test = model.predict(x_test, verbose=0)\n",
    "\n",
    "plt.figure(figsize=(30,20))\n",
    "plt.plot(y_pred_test, color='orange', label='Prediction')\n",
    "plt.plot(y_test, color='green', label='Ground Truth')\n",
    "plt.ylabel(\"RUL\")\n",
    "plt.xlabel(\"Unit Number\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
